# This script will perform a clustering of data based on their
# features. It proceeds in 3 steps:
#   1. feature reduction/selection
#   2. finding good numbers of clusters
#   3. finding a good clustering
#
# input : "data"    : a matrix whose rows correspond to the instances,
#                     columns to features
#         "minClusters": the minimum desired number of clusters
#         "maxClusters": the minimum desired number of clusters
#
# output: "clusters": the assignment of instances to clusters
#         "quality" : the quality measure
#
m<-dim(data)[1];#
safeExec({#
#
if( (m > 1) && (minClusters < m) ) {#
#
# 0. load packages
hasPackageStats<-safeUsePackage("stats");
hasPackageFpc<-safeUsePackage("fpc");
if(m < 10) { hasPackageMclust<-safeUsePackage("mclust"); }
else { hasPackageMclust<-FALSE; }
hasPackageApcluster<-safeUsePackage("apcluster");
hasPackageCluster<-safeUsePackage("cluster");
hasPackageNbClust<-safeUsePackage("NbClust");
#
## Step 1: Reduce number of features via Principal Component Analysis
## This step centers, scales, and rotates the data.
## It also discards the columns which have a very low standard deviation,
## i.e., which probably do not provide much information. Also handle
## the case where a column has 0 standard deviation.
if(hasPackageStats) {
  tryCatch(
    data <- prcomp(data, center=TRUE, scale=TRUE, tol=0.05)$x,
    error = function(e) {
     data <- prcomp(data, center=TRUE, tol=0.05)$x
    })
}
#
## If the number of clusters has been specified, then use it as-is
if(minClusters >= maxClusters) {
  cluster.n <- c(minClusters);
} else {
## ...otherwise
##
## Step 2: Determine how many clusters we need.
## Here we use five different approaches mainly based on
## http://stackoverflow.com/questions/15376075. Thus, we get five
## different suggestions about the preferred cluster number. We
## compute the median of these numbers and go with it.
#
cluster.n   <- integer(0);
#
# Determine the ideal number of clusters with the pamk function of the
# fpc package
if(hasPackageFpc) {
  safeExec( {
    suggested <- as.integer(pamk(data, minClusters:min(m-1,maxClusters))$nc);
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
  } )
}
#
# Determine the optimal number of clusters according to the Bayesian
# Information Criterion for expectation-maximization, initialized by
# hierarchical clustering for parameterized Gaussian mixture models.
if(hasPackageMclust) {
  safeExec( {
    suggested <- as.integer(dim(Mclust(data, G=minClusters:maxClusters)$z)[2]);
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
  } )
}
#
# Determine the ideal number of clusters by using Affinity propagation
# (AP) clustering, see http://dx.doi.org/10.1126/science.1136800.
if(hasPackageApcluster) {
  safeExec( {
    suggested <- as.integer(length(apcluster(negDistMat(r=2), data)@clusters));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
  } )
}
#
# using gap analysis
if(hasPackageCluster) {
  safeExec( {
    findCluster <- clusGap(data, kmeans, min(m-1,maxClusters), B=500, verbose=FALSE);
    suggested <- as.integer(maxSE(findCluster$Tab[, "gap"], findCluster$Tab[, "SE.sim"], method="Tibs2001SEmax"));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
    suggested <- as.integer(maxSE(findCluster$Tab[, "gap"], findCluster$Tab[, "SE.sim"], method="firstSEmax"));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
    suggested <- as.integer(maxSE(findCluster$Tab[, "gap"], findCluster$Tab[, "SE.sim"], method="globalSEmax"));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
    suggested <- as.integer(maxSE(findCluster$Tab[, "gap"], findCluster$Tab[, "SE.sim"], method="firstmax"));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
    suggested <- as.integer(maxSE(findCluster$Tab[, "gap"], findCluster$Tab[, "SE.sim"], method="globalmax"));
    if((suggested >= minClusters) && (suggested <= maxClusters)) {
      cluster.n <- c(cluster.n, suggested);
    }
    rm(findCluster);
  } )
}
#
if(hasPackageNbClust) {
  oldPlot <- plot;
  plot <- function(...) { }
  oldPar <- par;
  par <- function(...) { }
  safeExec( {
    cluster.nbEuc <- NbClust(data, diss=NULL,
                         distance="euclidean", min.nc=max(2, minClusters), max.nc=min(maxClusters, m-1),
                         method="kmeans", index="alllong")$Best.nc[1,];
    cluster.nbEuc <- unique(as.integer(cluster.nbEuc[
                which((cluster.nbEuc>=minClusters)&(cluster.nbEuc<=maxClusters))]));
    cluster.n <- c(cluster.n, min(maxClusters, max(minClusters, as.integer(round(median(cluster.nbEuc))))));
  } );
  plot <- oldPlot;
  rm(plot);
  par <- oldPar;
  rm(oldPar);
}
## Compute the cluster numbers to check: All unique suggestions, plus
## the (median-1)..(median+1) range.
if(length(cluster.n)>0) {
  cluster.n   <- min(maxClusters, max(minClusters, as.integer(cluster.n[which((cluster.n>=minClusters)&(cluster.n<=maxClusters))])));
  cluster.med <- min(maxClusters, max(minClusters, as.integer(round(median(cluster.n)))));
  cluster.n   <- c(cluster.n, max(minClusters, min(maxClusters, cluster.med-1)),
                              max(minClusters, min(maxClusters, cluster.med)),
                              max(minClusters, min(maxClusters, cluster.med+1)));
  rm(cluster.med);
}
if(exists("cluster.nbEuc")) {
  cluster.n <- c(cluster.n, cluster.nbEuc);
  rm(cluster.nbEuc);
}
if(length(cluster.n) > 0) {
  cluster.n <- as.integer(sort(unique(cluster.n)));
} else {
  cluster.n <- c(minClusters, minClusters+1);
  if(minClusters < (maxClusters-1)) {
    cluster.n <- c(cluster.n, minClusters+2);
    if(minClusters < (maxClusters-2)) {
      cluster.n <- c(cluster.n, minClusters+3);
      if(minClusters < (maxClusters-3)) {
        cluster.n <- c(cluster.n, minClusters+4);
      }
    }
  }
}
}
cluster.n<-sort(unique(cluster.n))
}# / get number of clusters
#
##
## Step 3: Perform the actual clustering. We do that for each unique
## suggested cluster number. From the results, we keep the best clustering,
## where we define "best" as the one with the largest silhouette.
#
if(hasPackageStats) {
  safeExec( distances <- dist(data) );
#
# try hierarchical clustering
  safeExec({#
    hclustList <- list(#
      hclust(distances, method="centroid"),#
      hclust(distances, method="ward.D"),#
      hclust(distances, method="ward.D2"),#
      hclust(distances, method="single"),#
      hclust(distances, method="complete"),#
      hclust(distances, method="average"),#
      hclust(distances, method="mcquitty"),#
      hclust(distances, method="median"));#
  });
#
for(number in cluster.n) {
# First we try kmeans.
  if(hasPackageStats) {
    safeExec( {
      currentClusters<-as.vector(kmeans(data, number)$cluster);
      if(exists("currentClusters")) {
        clusterN<-max(currentClusters);
        if( (clusterN >= minClusters) && (clusterN <= maxClusters) ) {
          if(clusterN > 1) {
            currentQuality<-as.double(cluster.stats(distances, currentClusters)$avg.silwidth);
          }
          if( (!(exists("currentQuality"))) || (length(currentQuality) <= 0) || (currentQuality < -1) || (currentQuality > 1) ) {
            currentQuality <- as.double(-1);
          }
          if( (!(exists("clusters"))) || (!(exists("quality")))  || (currentQuality > quality) ) {#
            quality<-currentQuality;#
            clusters<-currentClusters;#
          }
          rm(currentQuality);
        }
        rm(currentClusters);
      }
    });
  }
#
# Then we try pam.
  if(hasPackageCluster) {
    safeExec( {
      currentClusters<-as.vector(pam(data, number)$cluster);
      if(exists("currentClusters")) {
        clusterN<-max(currentClusters);
        if( (clusterN >= minClusters) && (clusterN <= maxClusters) ) {
          if(clusterN > 1) {
            currentQuality<-as.double(cluster.stats(distances, currentClusters)$avg.silwidth);
          }
          if( (!(exists("currentQuality"))) || (length(currentQuality) <= 0) || (currentQuality < -1) || (currentQuality > 1) ) {
            currentQuality <- as.double(-1);
          }
          if( (!(exists("clusters"))) || (!(exists("quality")))  || (currentQuality > quality) ) {#
            quality<-currentQuality;#
            clusters<-currentClusters;#
          }
          rm(currentQuality);
        }
        rm(currentClusters);
      }
    });
  }
#
# Then we try model-based clustering.
  if(hasPackageMclust) {
    safeExec( {
      currentClusters<-as.vector(Mclust(data, G=c(number), warn=FALSE)$classification);
      if(exists("currentClusters")) {
        clusterN<-max(currentClusters);
        if( (clusterN >= minClusters) && (clusterN <= maxClusters) ) {
          if(clusterN > 1) {
            currentQuality<-as.double(cluster.stats(distances, currentClusters)$avg.silwidth);
          }
          if( (!(exists("currentQuality"))) || (length(currentQuality) <= 0) || (currentQuality < -1) || (currentQuality > 1) ) {
            currentQuality <- as.double(-1);
          }
          if( (!(exists("clusters"))) || (!(exists("quality")))  || (currentQuality > quality) ) {#
            quality<-currentQuality;#
            clusters<-currentClusters;#
          }
          rm(currentQuality);
        }
        rm(currentClusters);
      }
    });
  }
#
# Finally, we try hierarchical clustering.
  if(hasPackageStats && exists("hclustList") && (number < m)) {
    for(hierarchicalClustering in hclustList) {#
      safeExec( {
        currentClusters <- as.vector(cutree(hierarchicalClustering, k=number));
        if(exists("currentClusters")) {
          clusterN<-max(currentClusters);
          if( (clusterN >= minClusters) && (clusterN <= maxClusters) ) {
            if(clusterN > 1) {
              currentQuality<-as.double(cluster.stats(distances, currentClusters)$avg.silwidth);
            } else {
              currentQuality<-as.double(-1);
            }
            if( (!(exists("currentQuality"))) || (length(currentQuality) <= 0) || (currentQuality < -1) || (currentQuality > 1) ) {
              currentQuality <- as.double(-1);
            }
            if( (!(exists("clusters"))) || (!(exists("quality")))  || (currentQuality > quality) ) {#
              quality<-currentQuality;#
              clusters<-currentClusters;#
            }
            rm(currentQuality);
          }
          rm(currentClusters);
        }
      });
    }
  }
}# / for  all cluster counts
#
safeExec( rm(distances) );
safeExec( rm(data) );
safeExec( rm(cluster.n) );
safeExec( rm(hclustList) );
#
}# / clusterable data
#
})# / safe exec wrapper
#
# fallback and error correction
if(!(safeExec( { # this should work
if( (!(exists("clusters"))) || (is.null(clusters)) || (!(is.vector(clusters))) || (length(clusters) != m) ) {
  useClusters = as.integer(0.5*(minClusters+maxClusters));
  clusters<-c(rep(1, m-useClusters), 1:useClusters);
  quality<-as.double(1);
} else {
  if( (!(exists("quality"))) || (is.null(quality)) || (length(quality) <= 0) || (quality < -1) || (quality > 1) ) {
    quality<-as.double(1);
  } else {
    quality<-as.double(max(0, min(1, (0.5-(0.5*quality)))));
  }
}
} ))) { # well, the above, oddly enough, did not work
  clusters<-rep(1, m);
  quality<-as.double(1);
}